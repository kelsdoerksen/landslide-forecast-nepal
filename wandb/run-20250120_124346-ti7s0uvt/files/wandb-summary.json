{"CV accuracies":[0.9010467380720545,0.8984907497565725,0.9014727361246349,0.9009250243427459,0.8934940052340089],"_step":2,"Test set F1":0.5572883513685551,"Average CV F1":0.5852388052613046,"_wandb":{"runtime":177},"_timestamp":1.7374060038413692e+09,"Average CV accuracy":0.8990858507060034,"roc_table":{"ncols":3,"nrows":333,"_type":"table-file","sha256":"f9f93150ad6297f35e1eda5ebfdcfbd22462bfa60577c8dc5b12d670aebab09a","size":6253,"artifact_path":"wandb-client-artifact://srdk4j0uh3iw8iu1rlgxgqfg3frcjawhw0wjli53r921h55hyrfg0zchyi13jtjvhprqipry8vyccsudvcgzki3n3q8h1662cjz94ng7qcu9iil5d21ix71b4dlk2nxc/roc_table.table.json","_latest_artifact_path":"wandb-client-artifact://xanj6ymqhzsqrpq8qapy6kiylbnci8ocnn8x34m4pff2ceyxjickhzhx5yeeuluap02nmx2vfbxby15hat0f58kf4m76enbsj67lu34owqj1qff8x8xp2jf71fw0319a:latest/roc_table.table.json","path":"media/table/roc_table_2_f9f93150ad6297f35e1e.table.json"},"Test set Accuracy":0.7713299358868979,"_runtime":177.057295}